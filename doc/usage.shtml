<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
 <!--#include virtual="./head.shtml" -->
 <script language="javascript">
  var update="10/22/2004";
 </script>
 <body id="usage">
  <div id="wrapper">
   <div id="main">
    <!-- Header -->
    <!--#include virtual="./header.shtml" -->

    
    <!--#include virtual="./navigation.shtml" -->
    <!-- Navigation --> 
    <div id="content">
     <h2>Usage</h2>
     <p>
      This page provides a quick howto for cpdetector. 
      Additional information may be found at the 
      <a href="docs.shtml">documentation</a> page.
     </p>
     <h3>Design notes</h3>
     <p>
      The framework is quite small, simple but clever.
      <ol>
       <li>
        An interface for code page - detection is the top entry point for all applications. 
        This interface has to be imported by applications that want to use cpdetector. 
       <li>
        A proxy implements this interface. It delegates the requests for code page - detection 
        to contained implementations that implement the different code page - detections techniques.
        The proxy may be configured with different concrete implementations to delegate requests to. 
        Currently a simple "first one returning non-null wins the decision" strategy is used. 
      	<li>
      	 Concrete implementations are shipped. A facade for the java port of mozilla's chardet 
      	 (<a href="http://jchardet.sourceforge.net" target="_blank">jchardet</a>) is provided that uses 
      	 exclusion and guessing by frequency analysis. Another implemenations is a facade to 
      	 a parser / lexer combination generated by an <a href="http://www.antlr.org" target="_blank">ANTLR</a> 
      	 - grammar that currently searches for the html charset attribute (xml-encoding to come if 
      	 feature request is made). 
      </ol>
     </p>
     <p>
     There are two ways to use cpdetecor:
     <ol>
      <li>
       <b>Taxonomy sorting:</b>
        The shipped <em>cpdetector.jar</em> may be used to start a command 
        line tool that searches a given directory recursively for input documents 
        and sorts these to an output directory into subfolders named after the 
        code page detected. Optionally the documents may be transformed to a desired 
        target code page. <br>
        This tool was used by me for sorting a huge collection of crawled documents 
        after their codepage and perform tests with documents in specific code pages 
        (unicode normalisation performance tests for documents in different encodings).
       <li>
        <b>Application integration:</b>
         The framework may be configured and integrated into your application in order 
         to perform operations depending on the codepage. Maybe you want to add code page - detection 
         as a feature to a search engine. Feel the power of internationalization for only 0 cent 
         per license. Order now! <span style="color:#fff">I will never become a salesman.</span>
     </ol>
     </p>
     <h3>Taxonomy sorting</h3>
     <p>
      cpdetector.jar - which may be <a href="download.shtml">downloaded</a> from the binary release at 
      sourceforge - may be used to sort documents by their detected codepage. Simply invoke the following 
      command:
      <pre>
 java -jar cpdetector.jar 
      </pre>
      As you did not specify mandatory arguments you will see a usage output: 
      <pre>

usage: java -jar codepageProcessor.jar [options]
options:

  Optional:
  -e &lt;extensions&gt; : A comma- or semicolon- separated string for document extensions 
                    like "-e txt,dat" (without dot or space!).
  -m              : Move files with unknown charset to directory "unknown".
  -v              : Verbose output.
  -w &lt;int&gt;        : Wait &lt;int&gt; seconds before trying next document 
                    (good, if you want to work on the very same machine).

  -t &lt;charset&gt;    : Try to transform the document to given charset (code page) name.
                    This is only possible for documents that are detected to have a
                    code page that is supported by the current java VM. If not possible
                    sorting will be done as normal.
  -c              : Semicolon-separated list of fully qualified classnames. 
                    These classenames will be instantiadet, casted to ICodepageDetector instances
                    and used to detect the code page of documents in the order specified.
                    If this argument is ommited, a HTMLCodepageDetector followed by .
                    a JChardetFacade is used by default.
  Mandatory:
  -r            : Root directory containing the collection (recursive).
  -o            : Output directory containing the sorted collection.

      </pre>
     </p>
     
     <h3>Application integration</h3>
     <p>
      The following demo - code shows, how to configure the proxy for code page detection and how to 
      use it. The example is kept simple. If you want to reuse the proxy, just keep it as a m
      member of a class that provides a service that involves code page - detection.
      
      <pre>
import cpdetector.io.*;

public class myUsage{
  // Create the proxy:
  CodepageDetectorProxy detector = CodepageDetectorProxy.getInstance(); // A singleton.
  
  // constructor:
  public myUsage(){
    // Add the implementations of cpdetector.io.ICodepageDetector: 
    // The first instance delegated to tries to detect the meta charset attribut in html pages.
    detector.add(new ParsingDetector(true)); // be verbose about parsing.
    // This one does the tricks of exclusion and frequency detection, if first implementation is 
    // unsucessful:
    detector.add(JChardetFacade.getInstance()); // Another singleton.
    detector.add(ASCIIDetector.getInstance()); // Fallback, see <a href="http://cpdetector.sourceforge.net/doc/javadoc/index.html?cpdetector/io/ASCIIDetector.html" target="_blank">javadoc</a>.
  }
...
  public boolean someMethod(File document){
    boolean ret = false;
    // Work with the configured proxy: 
    java.nio.charset.Charset charset = null;
    charset = detector.detectCodepage(document.toURL());
    if(charset == null){
      project.forName("cpdetector").report("bogus document",document.toUrl());
    }
    else{
      // Open the document in the given code page:
      java.io.Reader reader = new java.io.InputStreamReader(new java.io.FileInputStream(document),charset);
      // Read from it, do sth., whatever you desire. The character are now - hopefully - correct..
      ret = true;
    }
    return ret;
  }
  ... 
}

      </pre>
      In order to compile this example, you have to put cpdetector.jar into your classpath. 
      Your IDE will certainly support inclusion of *.jar files into your javac classpath.
     </p>
    </div>
    <!-- End of contents div -->
    <!-- The counter -->
    <!--#include virtual="./footer.shtml" -->
   </div>
   <!-- End of main div -->
  </div>	
  <!-- End of wrapper div -->
 </body>
</html>